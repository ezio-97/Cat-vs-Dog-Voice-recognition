{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7706f629",
   "metadata": {},
   "source": [
    "* Compile, Train and Save the models here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01926d77",
   "metadata": {},
   "source": [
    "* 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2d6e8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # CSV file\n",
    "import config\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a609b9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scale_and_PCALDA(path):\n",
    "\n",
    "    data = pd.read_csv(path)\n",
    "    num_columns = data.shape[1]\n",
    "    print(f\"Num of Columns is {num_columns}\")\n",
    "    X = np.array(data.iloc[:,0:num_columns-1])\n",
    "    y = np.array(data.iloc[:,num_columns-1])\n",
    "    # print(len(X[0]))\n",
    "    # print(y[0])\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)  # X shape: (n_samples, 12)\n",
    "\n",
    "    ''' PCA '''\n",
    "    n_components = 2\n",
    "    pca_object = PCA(n_components= n_components)\n",
    "    pca_object.fit(X_scaled)\n",
    "    PrincipleComps = pca_object.transform(X_scaled)\n",
    "    classes = np.unique(y)\n",
    "\n",
    "    for i in range(n_components):\n",
    "        plt.figure()\n",
    "        for clss in classes:\n",
    "            plt.hist(PrincipleComps[y == clss, i],\n",
    "                    bins=\"auto\", alpha=0.5, \n",
    "                    label=f\"Class {clss}\")\n",
    "        plt.xlabel(\"Feature intervals\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.title(f\"PCA by Class for feature column {i}\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    score = davies_bouldin_score(PrincipleComps, y)\n",
    "    print(f\"The davies_bouldin_score for PCA is {score}\")\n",
    "\n",
    "\n",
    "    \"\"\" LDA \"\"\"\n",
    "\n",
    "    lda_mcc = LDA()\n",
    "    lda_mcc.fit(X_scaled,y)\n",
    "    lda_OP = lda_mcc.transform(X_scaled)\n",
    "    plt.figure()\n",
    "    for c in classes:\n",
    "        plt.hist(lda_OP[y == c], bins=20, alpha=0.5, label=f\"Class {c}\")\n",
    "    plt.xlabel(\"1D LDA Projection\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"LDA Projection onto First Component. 0 is cat, 1 is Dog\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3eed159",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(\"Original DATA\")\n",
    "# Scale_and_PCALDA(path = config.Features + 'data.csv' )\n",
    "\n",
    "# print(\"fs300_cc12\")\n",
    "# Scale_and_PCALDA(path = config.Features + 'data_fs300_cc12.csv')\n",
    "\n",
    "# print(\"fs300_cc20\")\n",
    "# Scale_and_PCALDA(path = config.Features + 'data_fs300_cc20.csv')\n",
    "\n",
    "# print(\"fs300_cc30\")\n",
    "# Scale_and_PCALDA(path = config.Features + 'data_fs300_cc30.csv')\n",
    "\n",
    "# print(\"fs500_cc20\")\n",
    "# Scale_and_PCALDA(path = config.Features + 'data_fs500_cc20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f1ac39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_and_Train(data, Epochs): \n",
    "    num_columns = data.shape[1]\n",
    "    X = data.iloc[:,0:num_columns-1]\n",
    "    y = data.iloc[:,num_columns-1]\n",
    "    mask = X.iloc[:, -4:].sum(axis=1) != 0\n",
    "    X = np.array(X[mask])\n",
    "    y = np.array(y[mask])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)  \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y,\n",
    "        test_size=0.2,         \n",
    "        stratify=y    \n",
    "    )\n",
    "\n",
    "    model = Sequential([\n",
    "\n",
    "        Dense(96, input_shape=(20,), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Dense(64, activation='tanh'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Dense(32, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Dense(1, activation='sigmoid')  # Binary classification\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    # Early stopping to prevent overfitting\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        validation_split=0.2,\n",
    "                        epochs=Epochs,\n",
    "                        batch_size=32,\n",
    "                        callbacks=[early_stop],\n",
    "                        verbose=1)\n",
    "    print('')\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbac18a",
   "metadata": {},
   "source": [
    "* 2. Training the model\n",
    "\n",
    "* First approach- Vanilla NN \n",
    "* fs300_cc20 looks good. Let us see...................."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0149072a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\desly\\ml_lab\\lab-env\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6778 - loss: 0.6699 - val_accuracy: 0.8358 - val_loss: 0.3885\n",
      "Epoch 2/80\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8058 - loss: 0.4516 - val_accuracy: 0.8501 - val_loss: 0.3435\n",
      "Epoch 3/80\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8185 - loss: 0.4302 - val_accuracy: 0.8596 - val_loss: 0.3231\n",
      "Epoch 4/80\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8374 - loss: 0.3994 - val_accuracy: 0.8711 - val_loss: 0.3066\n",
      "Epoch 5/80\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8425 - loss: 0.3888 - val_accuracy: 0.8738 - val_loss: 0.2939\n",
      "Epoch 6/80\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8457 - loss: 0.3671 - val_accuracy: 0.8813 - val_loss: 0.2857\n",
      "Epoch 7/80\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8440 - loss: 0.3638 - val_accuracy: 0.8881 - val_loss: 0.2756\n",
      "Epoch 8/80\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8500 - loss: 0.3571 - val_accuracy: 0.8955 - val_loss: 0.2699\n",
      "Epoch 9/80\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8591 - loss: 0.3488 - val_accuracy: 0.8908 - val_loss: 0.2656\n",
      "Epoch 10/80\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8728 - loss: 0.3252 - val_accuracy: 0.8935 - val_loss: 0.2634\n",
      "Epoch 11/80\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8681 - loss: 0.3298 - val_accuracy: 0.8935 - val_loss: 0.2561\n",
      "Epoch 12/80\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8766 - loss: 0.3038 - val_accuracy: 0.8976 - val_loss: 0.2538\n",
      "Epoch 13/80\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8722 - loss: 0.3190 - val_accuracy: 0.8976 - val_loss: 0.2521\n",
      "Epoch 14/80\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8784 - loss: 0.3005 - val_accuracy: 0.9016 - val_loss: 0.2434\n",
      "Epoch 15/80\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8833 - loss: 0.2980 - val_accuracy: 0.9003 - val_loss: 0.2498\n",
      "Epoch 16/80\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8832 - loss: 0.3044 - val_accuracy: 0.9037 - val_loss: 0.2426\n",
      "Epoch 17/80\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8849 - loss: 0.2873 - val_accuracy: 0.9030 - val_loss: 0.2392\n",
      "Epoch 18/80\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8819 - loss: 0.2984 - val_accuracy: 0.9043 - val_loss: 0.2343\n",
      "Epoch 19/80\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8732 - loss: 0.2933 - val_accuracy: 0.9030 - val_loss: 0.2347\n",
      "Epoch 20/80\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8825 - loss: 0.2967 - val_accuracy: 0.9043 - val_loss: 0.2363\n",
      "Epoch 21/80\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8785 - loss: 0.2962 - val_accuracy: 0.9030 - val_loss: 0.2393\n",
      "Epoch 22/80\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8933 - loss: 0.2807 - val_accuracy: 0.9043 - val_loss: 0.2336\n",
      "Epoch 23/80\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8885 - loss: 0.2911 - val_accuracy: 0.9050 - val_loss: 0.2338\n",
      "Epoch 24/80\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8866 - loss: 0.2754 - val_accuracy: 0.9050 - val_loss: 0.2348\n",
      "Epoch 25/80\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8917 - loss: 0.2820 - val_accuracy: 0.9077 - val_loss: 0.2350\n",
      "Epoch 26/80\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8879 - loss: 0.2874 - val_accuracy: 0.9030 - val_loss: 0.2330\n",
      "Epoch 27/80\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9005 - loss: 0.2614 - val_accuracy: 0.9043 - val_loss: 0.2316\n",
      "Epoch 28/80\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8891 - loss: 0.2825 - val_accuracy: 0.9098 - val_loss: 0.2210\n",
      "Epoch 29/80\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8886 - loss: 0.2795 - val_accuracy: 0.9009 - val_loss: 0.2275\n",
      "Epoch 30/80\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8994 - loss: 0.2586 - val_accuracy: 0.9064 - val_loss: 0.2273\n",
      "Epoch 31/80\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8895 - loss: 0.2801 - val_accuracy: 0.9057 - val_loss: 0.2284\n",
      "Epoch 32/80\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8882 - loss: 0.2669 - val_accuracy: 0.9118 - val_loss: 0.2217\n",
      "Epoch 33/80\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8982 - loss: 0.2676 - val_accuracy: 0.9091 - val_loss: 0.2224\n",
      "\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9104 - loss: 0.2534\n",
      "Test Accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(config.Features + 'data_fs300_cc20.csv')\n",
    "Load_and_Train(data, 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab369a8e",
   "metadata": {},
   "source": [
    "* Second approach- Vanilla NN and fs500_cc20 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "780c2174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\desly\\ml_lab\\lab-env\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6759 - loss: 0.6285 - val_accuracy: 0.8308 - val_loss: 0.4282\n",
      "Epoch 2/80\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8107 - loss: 0.4426 - val_accuracy: 0.8538 - val_loss: 0.3655\n",
      "Epoch 3/80\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8297 - loss: 0.4056 - val_accuracy: 0.8622 - val_loss: 0.3458\n",
      "Epoch 4/80\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8402 - loss: 0.4003 - val_accuracy: 0.8720 - val_loss: 0.3273\n",
      "Epoch 5/80\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8478 - loss: 0.3776 - val_accuracy: 0.8790 - val_loss: 0.3130\n",
      "Epoch 6/80\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8524 - loss: 0.3646 - val_accuracy: 0.8797 - val_loss: 0.3048\n",
      "Epoch 7/80\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8584 - loss: 0.3416 - val_accuracy: 0.8783 - val_loss: 0.2904\n",
      "Epoch 8/80\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8627 - loss: 0.3561 - val_accuracy: 0.8846 - val_loss: 0.2871\n",
      "Epoch 9/80\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8768 - loss: 0.3147 - val_accuracy: 0.8881 - val_loss: 0.2812\n",
      "Epoch 10/80\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8693 - loss: 0.3157 - val_accuracy: 0.8902 - val_loss: 0.2783\n",
      "Epoch 11/80\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8654 - loss: 0.3291 - val_accuracy: 0.8951 - val_loss: 0.2764\n",
      "Epoch 12/80\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8711 - loss: 0.3173 - val_accuracy: 0.8923 - val_loss: 0.2689\n",
      "Epoch 13/80\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8745 - loss: 0.3098 - val_accuracy: 0.8979 - val_loss: 0.2624\n",
      "Epoch 14/80\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8724 - loss: 0.3106 - val_accuracy: 0.8993 - val_loss: 0.2659\n",
      "Epoch 15/80\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8746 - loss: 0.3155 - val_accuracy: 0.9000 - val_loss: 0.2642\n",
      "Epoch 16/80\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8865 - loss: 0.2896 - val_accuracy: 0.8993 - val_loss: 0.2670\n",
      "Epoch 17/80\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8888 - loss: 0.2802 - val_accuracy: 0.8993 - val_loss: 0.2594\n",
      "Epoch 18/80\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8782 - loss: 0.3027 - val_accuracy: 0.9042 - val_loss: 0.2558\n",
      "Epoch 19/80\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8833 - loss: 0.2926 - val_accuracy: 0.9007 - val_loss: 0.2556\n",
      "Epoch 20/80\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8881 - loss: 0.2752 - val_accuracy: 0.9042 - val_loss: 0.2570\n",
      "Epoch 21/80\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8844 - loss: 0.2828 - val_accuracy: 0.9042 - val_loss: 0.2465\n",
      "Epoch 22/80\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8755 - loss: 0.2957 - val_accuracy: 0.9049 - val_loss: 0.2520\n",
      "Epoch 23/80\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8860 - loss: 0.2856 - val_accuracy: 0.9021 - val_loss: 0.2546\n",
      "Epoch 24/80\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8822 - loss: 0.2850 - val_accuracy: 0.9049 - val_loss: 0.2477\n",
      "Epoch 25/80\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8969 - loss: 0.2725 - val_accuracy: 0.9056 - val_loss: 0.2465\n",
      "Epoch 26/80\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8867 - loss: 0.2868 - val_accuracy: 0.9035 - val_loss: 0.2463\n",
      "Epoch 27/80\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8978 - loss: 0.2589 - val_accuracy: 0.9049 - val_loss: 0.2503\n",
      "Epoch 28/80\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8905 - loss: 0.2753 - val_accuracy: 0.9070 - val_loss: 0.2424\n",
      "Epoch 29/80\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9026 - loss: 0.2494 - val_accuracy: 0.9056 - val_loss: 0.2463\n",
      "Epoch 30/80\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8958 - loss: 0.2715 - val_accuracy: 0.9028 - val_loss: 0.2491\n",
      "Epoch 31/80\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8926 - loss: 0.2698 - val_accuracy: 0.9014 - val_loss: 0.2470\n",
      "Epoch 32/80\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8948 - loss: 0.2662 - val_accuracy: 0.9035 - val_loss: 0.2437\n",
      "Epoch 33/80\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8915 - loss: 0.2665 - val_accuracy: 0.9063 - val_loss: 0.2460\n",
      "\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9118 - loss: 0.2222\n",
      "Test Accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(config.Features + 'data_fs500_cc20.csv')\n",
    "Load_and_Train(data, 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe4570e",
   "metadata": {},
   "source": [
    "* 3rd approach- Vanilla NN and Random sampled dataset fs300_cc20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a857866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\desly\\ml_lab\\lab-env\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7689 - loss: 0.5188 - val_accuracy: 0.8902 - val_loss: 0.2812\n",
      "Epoch 2/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8697 - loss: 0.3335 - val_accuracy: 0.9047 - val_loss: 0.2540\n",
      "Epoch 3/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8812 - loss: 0.3109 - val_accuracy: 0.9103 - val_loss: 0.2387\n",
      "Epoch 4/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8894 - loss: 0.2891 - val_accuracy: 0.9131 - val_loss: 0.2299\n",
      "Epoch 5/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8909 - loss: 0.2850 - val_accuracy: 0.9195 - val_loss: 0.2166\n",
      "Epoch 6/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8924 - loss: 0.2758 - val_accuracy: 0.9196 - val_loss: 0.2086\n",
      "Epoch 7/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8960 - loss: 0.2680 - val_accuracy: 0.9233 - val_loss: 0.2072\n",
      "Epoch 8/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8943 - loss: 0.2635 - val_accuracy: 0.9233 - val_loss: 0.2015\n",
      "Epoch 9/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9022 - loss: 0.2560 - val_accuracy: 0.9269 - val_loss: 0.1930\n",
      "Epoch 10/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9019 - loss: 0.2494 - val_accuracy: 0.9302 - val_loss: 0.1887\n",
      "Epoch 11/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.2416 - val_accuracy: 0.9304 - val_loss: 0.1885\n",
      "Epoch 12/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9062 - loss: 0.2426 - val_accuracy: 0.9302 - val_loss: 0.1845\n",
      "Epoch 13/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9087 - loss: 0.2369 - val_accuracy: 0.9311 - val_loss: 0.1781\n",
      "Epoch 14/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2324 - val_accuracy: 0.9300 - val_loss: 0.1822\n",
      "Epoch 15/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2327 - val_accuracy: 0.9313 - val_loss: 0.1741\n",
      "Epoch 16/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2329 - val_accuracy: 0.9376 - val_loss: 0.1734\n",
      "Epoch 17/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9178 - loss: 0.2216 - val_accuracy: 0.9334 - val_loss: 0.1744\n",
      "Epoch 18/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2253 - val_accuracy: 0.9350 - val_loss: 0.1669\n",
      "Epoch 19/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2233 - val_accuracy: 0.9338 - val_loss: 0.1709\n",
      "Epoch 20/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2190 - val_accuracy: 0.9374 - val_loss: 0.1622\n",
      "Epoch 21/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2246 - val_accuracy: 0.9361 - val_loss: 0.1625\n",
      "Epoch 22/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9174 - loss: 0.2160 - val_accuracy: 0.9380 - val_loss: 0.1579\n",
      "Epoch 23/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9175 - loss: 0.2205 - val_accuracy: 0.9371 - val_loss: 0.1584\n",
      "Epoch 24/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9193 - loss: 0.2119 - val_accuracy: 0.9409 - val_loss: 0.1557\n",
      "Epoch 25/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9222 - loss: 0.2091 - val_accuracy: 0.9447 - val_loss: 0.1521\n",
      "Epoch 26/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9180 - loss: 0.2189 - val_accuracy: 0.9418 - val_loss: 0.1553\n",
      "Epoch 27/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9188 - loss: 0.2157 - val_accuracy: 0.9422 - val_loss: 0.1526\n",
      "Epoch 28/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9236 - loss: 0.1997 - val_accuracy: 0.9403 - val_loss: 0.1514\n",
      "Epoch 29/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9183 - loss: 0.2136 - val_accuracy: 0.9411 - val_loss: 0.1531\n",
      "Epoch 30/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9235 - loss: 0.2056 - val_accuracy: 0.9418 - val_loss: 0.1534\n",
      "Epoch 31/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9254 - loss: 0.2042 - val_accuracy: 0.9449 - val_loss: 0.1453\n",
      "Epoch 32/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9208 - loss: 0.2091 - val_accuracy: 0.9436 - val_loss: 0.1467\n",
      "Epoch 33/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9213 - loss: 0.2062 - val_accuracy: 0.9422 - val_loss: 0.1455\n",
      "Epoch 34/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9251 - loss: 0.1998 - val_accuracy: 0.9447 - val_loss: 0.1468\n",
      "Epoch 35/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9254 - loss: 0.1972 - val_accuracy: 0.9476 - val_loss: 0.1423\n",
      "Epoch 36/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9218 - loss: 0.2066 - val_accuracy: 0.9470 - val_loss: 0.1413\n",
      "Epoch 37/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9204 - loss: 0.2100 - val_accuracy: 0.9455 - val_loss: 0.1432\n",
      "Epoch 38/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9257 - loss: 0.1971 - val_accuracy: 0.9460 - val_loss: 0.1409\n",
      "Epoch 39/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9235 - loss: 0.1991 - val_accuracy: 0.9464 - val_loss: 0.1453\n",
      "Epoch 40/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9276 - loss: 0.1913 - val_accuracy: 0.9483 - val_loss: 0.1431\n",
      "Epoch 41/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9264 - loss: 0.1951 - val_accuracy: 0.9485 - val_loss: 0.1377\n",
      "Epoch 42/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9287 - loss: 0.1918 - val_accuracy: 0.9483 - val_loss: 0.1381\n",
      "Epoch 43/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9249 - loss: 0.1983 - val_accuracy: 0.9487 - val_loss: 0.1383\n",
      "Epoch 44/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9242 - loss: 0.1980 - val_accuracy: 0.9489 - val_loss: 0.1356\n",
      "Epoch 45/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9282 - loss: 0.1928 - val_accuracy: 0.9504 - val_loss: 0.1339\n",
      "Epoch 46/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9297 - loss: 0.1900 - val_accuracy: 0.9487 - val_loss: 0.1357\n",
      "Epoch 47/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9286 - loss: 0.1937 - val_accuracy: 0.9506 - val_loss: 0.1341\n",
      "Epoch 48/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9253 - loss: 0.1936 - val_accuracy: 0.9474 - val_loss: 0.1386\n",
      "Epoch 49/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9296 - loss: 0.1878 - val_accuracy: 0.9478 - val_loss: 0.1364\n",
      "Epoch 50/80\n",
      "\u001b[1m654/654\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9318 - loss: 0.1880 - val_accuracy: 0.9482 - val_loss: 0.1379\n",
      "\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9467 - loss: 0.1445  \n",
      "Test Accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(config.Features + 'Rdata_fs300_cc20.csv')\n",
    "Load_and_Train(data, 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608f0fca",
   "metadata": {},
   "source": [
    "* Approach 3 - 2D convolutional model and fs300cc20f20 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad9b2ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalize(feature):\n",
    "    min_val = np.min(feature)\n",
    "    max_val = np.max(feature)\n",
    "    return (feature - min_val) / (max_val - min_val + 1e-8)  # add epsilon to avoid division by zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47dd488b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 20)\n"
     ]
    }
   ],
   "source": [
    "features = np.load(config.Features + '2Ddata_fs300_cc20_f50/features.npy')  \n",
    "labels = np.load(config.Features + '2Ddata_fs300_cc20_f50/labels.npy')    \n",
    "# print(features[0])\n",
    "X_scaled = min_max_normalize(features)\n",
    "print(X_scaled[0].shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39aa1396",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\desly\\ml_lab\\lab-env\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6912</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">442,432</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6912\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m442,432\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">442,657</span> (1.69 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m442,657\u001b[0m (1.69 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">442,657</span> (1.69 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m442,657\u001b[0m (1.69 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Define input shape\n",
    "input_shape = (features.shape[1], features.shape[2], 1)  # Add channel dimension for CNNs\n",
    "\n",
    "# Reshape features for CNN: (samples, height, width, channels)\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]\n",
    "\n",
    "# Example model structure\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (2, 2), activation='relu', input_shape=input_shape),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # for binary classification (cat vs dog)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d2606eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5189 - loss: 0.7251 - val_accuracy: 0.6029 - val_loss: 0.6713\n",
      "Epoch 2/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5866 - loss: 0.6772 - val_accuracy: 0.6029 - val_loss: 0.6656\n",
      "Epoch 3/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6213 - loss: 0.6577 - val_accuracy: 0.6029 - val_loss: 0.6679\n",
      "Epoch 4/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5762 - loss: 0.6679 - val_accuracy: 0.6029 - val_loss: 0.6463\n",
      "Epoch 5/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5855 - loss: 0.6517 - val_accuracy: 0.6029 - val_loss: 0.6206\n",
      "Epoch 6/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5683 - loss: 0.6253 - val_accuracy: 0.6029 - val_loss: 0.5739\n",
      "Epoch 7/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6172 - loss: 0.5718 - val_accuracy: 0.7653 - val_loss: 0.5256\n",
      "Epoch 8/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6990 - loss: 0.5154 - val_accuracy: 0.7581 - val_loss: 0.4713\n",
      "Epoch 9/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7414 - loss: 0.4783 - val_accuracy: 0.8087 - val_loss: 0.4345\n",
      "Epoch 10/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7839 - loss: 0.4420 - val_accuracy: 0.8773 - val_loss: 0.4173\n",
      "Epoch 11/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8485 - loss: 0.4218 - val_accuracy: 0.9025 - val_loss: 0.4063\n",
      "Epoch 12/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8800 - loss: 0.4044 - val_accuracy: 0.8628 - val_loss: 0.3816\n",
      "Epoch 13/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8641 - loss: 0.3917 - val_accuracy: 0.8664 - val_loss: 0.3716\n",
      "Epoch 14/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8776 - loss: 0.3731 - val_accuracy: 0.8664 - val_loss: 0.3631\n",
      "Epoch 15/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8820 - loss: 0.3812 - val_accuracy: 0.9134 - val_loss: 0.3566\n",
      "Epoch 16/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8956 - loss: 0.3646 - val_accuracy: 0.8809 - val_loss: 0.3449\n",
      "Epoch 17/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8912 - loss: 0.3610 - val_accuracy: 0.8809 - val_loss: 0.3382\n",
      "Epoch 18/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9001 - loss: 0.3286 - val_accuracy: 0.8845 - val_loss: 0.3317\n",
      "Epoch 19/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8953 - loss: 0.3333 - val_accuracy: 0.9134 - val_loss: 0.3259\n",
      "Epoch 20/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8909 - loss: 0.3505 - val_accuracy: 0.8809 - val_loss: 0.3196\n",
      "Epoch 21/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8920 - loss: 0.3309 - val_accuracy: 0.9134 - val_loss: 0.3144\n",
      "Epoch 22/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9172 - loss: 0.3138 - val_accuracy: 0.9134 - val_loss: 0.3075\n",
      "Epoch 23/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9089 - loss: 0.3222 - val_accuracy: 0.9061 - val_loss: 0.3019\n",
      "Epoch 24/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9111 - loss: 0.3008 - val_accuracy: 0.9134 - val_loss: 0.2970\n",
      "Epoch 25/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9007 - loss: 0.3189 - val_accuracy: 0.9134 - val_loss: 0.2918\n",
      "Epoch 26/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9100 - loss: 0.3086 - val_accuracy: 0.9134 - val_loss: 0.2864\n",
      "Epoch 27/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9103 - loss: 0.3053 - val_accuracy: 0.9206 - val_loss: 0.2823\n",
      "Epoch 28/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9176 - loss: 0.2924 - val_accuracy: 0.9170 - val_loss: 0.2782\n",
      "Epoch 29/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9381 - loss: 0.2785 - val_accuracy: 0.9242 - val_loss: 0.2744\n",
      "Epoch 30/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9392 - loss: 0.2794 - val_accuracy: 0.9278 - val_loss: 0.2700\n",
      "Epoch 31/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9342 - loss: 0.2705 - val_accuracy: 0.9278 - val_loss: 0.2652\n",
      "Epoch 32/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9276 - loss: 0.2710 - val_accuracy: 0.9278 - val_loss: 0.2618\n",
      "Epoch 33/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9158 - loss: 0.2705 - val_accuracy: 0.9278 - val_loss: 0.2588\n",
      "Epoch 34/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9258 - loss: 0.2743 - val_accuracy: 0.9278 - val_loss: 0.2547\n",
      "Epoch 35/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9294 - loss: 0.2770 - val_accuracy: 0.9278 - val_loss: 0.2529\n",
      "Epoch 36/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9353 - loss: 0.2493 - val_accuracy: 0.9314 - val_loss: 0.2458\n",
      "Epoch 37/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9251 - loss: 0.2616 - val_accuracy: 0.9314 - val_loss: 0.2440\n",
      "Epoch 38/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9304 - loss: 0.2506 - val_accuracy: 0.9386 - val_loss: 0.2390\n",
      "Epoch 39/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9427 - loss: 0.2348 - val_accuracy: 0.9314 - val_loss: 0.2362\n",
      "Epoch 40/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9339 - loss: 0.2497 - val_accuracy: 0.9495 - val_loss: 0.2342\n",
      "Epoch 41/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9314 - loss: 0.2434 - val_accuracy: 0.9314 - val_loss: 0.2304\n",
      "Epoch 42/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9339 - loss: 0.2431 - val_accuracy: 0.9458 - val_loss: 0.2278\n",
      "Epoch 43/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9327 - loss: 0.2455 - val_accuracy: 0.9350 - val_loss: 0.2252\n",
      "Epoch 44/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9398 - loss: 0.2444 - val_accuracy: 0.9350 - val_loss: 0.2257\n",
      "Epoch 45/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9388 - loss: 0.2364 - val_accuracy: 0.9350 - val_loss: 0.2256\n",
      "Epoch 46/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9329 - loss: 0.2359 - val_accuracy: 0.9458 - val_loss: 0.2176\n",
      "Epoch 47/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9428 - loss: 0.2336 - val_accuracy: 0.9350 - val_loss: 0.2177\n",
      "Epoch 48/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9510 - loss: 0.2153 - val_accuracy: 0.9495 - val_loss: 0.2112\n",
      "Epoch 49/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9283 - loss: 0.2323 - val_accuracy: 0.9422 - val_loss: 0.2112\n",
      "Epoch 50/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9506 - loss: 0.2146 - val_accuracy: 0.9458 - val_loss: 0.2078\n",
      "Epoch 51/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9484 - loss: 0.2211 - val_accuracy: 0.9567 - val_loss: 0.2047\n",
      "Epoch 52/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9474 - loss: 0.2113 - val_accuracy: 0.9314 - val_loss: 0.2076\n",
      "Epoch 53/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9392 - loss: 0.2129 - val_accuracy: 0.9567 - val_loss: 0.2010\n",
      "Epoch 54/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9494 - loss: 0.1995 - val_accuracy: 0.9314 - val_loss: 0.2031\n",
      "Epoch 55/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9380 - loss: 0.2172 - val_accuracy: 0.9531 - val_loss: 0.1961\n",
      "Epoch 56/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9534 - loss: 0.2044 - val_accuracy: 0.9531 - val_loss: 0.1941\n",
      "Epoch 57/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9526 - loss: 0.1996 - val_accuracy: 0.9531 - val_loss: 0.1965\n",
      "Epoch 58/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9401 - loss: 0.2019 - val_accuracy: 0.9531 - val_loss: 0.1938\n",
      "Epoch 59/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9556 - loss: 0.1836 - val_accuracy: 0.9531 - val_loss: 0.1873\n",
      "Epoch 60/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9468 - loss: 0.1899 - val_accuracy: 0.9531 - val_loss: 0.1848\n",
      "Epoch 61/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9417 - loss: 0.1949 - val_accuracy: 0.9531 - val_loss: 0.1839\n",
      "Epoch 62/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9444 - loss: 0.1954 - val_accuracy: 0.9531 - val_loss: 0.1804\n",
      "Epoch 63/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9558 - loss: 0.1781 - val_accuracy: 0.9531 - val_loss: 0.1781\n",
      "Epoch 64/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9527 - loss: 0.1770 - val_accuracy: 0.9567 - val_loss: 0.1751\n",
      "Epoch 65/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9646 - loss: 0.1636 - val_accuracy: 0.9567 - val_loss: 0.1772\n",
      "Epoch 66/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9513 - loss: 0.1801 - val_accuracy: 0.9350 - val_loss: 0.1789\n",
      "Epoch 67/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9524 - loss: 0.1716 - val_accuracy: 0.9567 - val_loss: 0.1705\n",
      "Epoch 68/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9641 - loss: 0.1656 - val_accuracy: 0.9567 - val_loss: 0.1666\n",
      "Epoch 69/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9643 - loss: 0.1730 - val_accuracy: 0.9567 - val_loss: 0.1701\n",
      "Epoch 70/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9565 - loss: 0.1676 - val_accuracy: 0.9314 - val_loss: 0.1678\n",
      "Epoch 71/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9475 - loss: 0.1763 - val_accuracy: 0.9567 - val_loss: 0.1636\n",
      "Epoch 72/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9574 - loss: 0.1568 - val_accuracy: 0.9603 - val_loss: 0.1598\n",
      "Epoch 73/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9659 - loss: 0.1499 - val_accuracy: 0.9567 - val_loss: 0.1606\n",
      "Epoch 74/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9778 - loss: 0.1297 - val_accuracy: 0.9567 - val_loss: 0.1629\n",
      "Epoch 75/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9658 - loss: 0.1467 - val_accuracy: 0.9603 - val_loss: 0.1548\n",
      "Epoch 76/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9589 - loss: 0.1444 - val_accuracy: 0.9495 - val_loss: 0.1311\n",
      "Epoch 77/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9628 - loss: 0.1218 - val_accuracy: 0.9495 - val_loss: 0.1402\n",
      "Epoch 78/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9580 - loss: 0.1296 - val_accuracy: 0.9350 - val_loss: 0.1453\n",
      "Epoch 79/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9539 - loss: 0.1235 - val_accuracy: 0.9495 - val_loss: 0.1339\n",
      "Epoch 80/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9649 - loss: 0.1146 - val_accuracy: 0.9567 - val_loss: 0.1226\n",
      "Epoch 81/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9610 - loss: 0.1149 - val_accuracy: 0.9567 - val_loss: 0.1182\n",
      "Epoch 82/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9659 - loss: 0.0973 - val_accuracy: 0.9603 - val_loss: 0.1151\n",
      "Epoch 83/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9589 - loss: 0.1166 - val_accuracy: 0.9350 - val_loss: 0.1133\n",
      "Epoch 84/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9593 - loss: 0.0988 - val_accuracy: 0.9603 - val_loss: 0.1124\n",
      "Epoch 85/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9609 - loss: 0.1076 - val_accuracy: 0.9350 - val_loss: 0.1112\n",
      "Epoch 86/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9673 - loss: 0.0852 - val_accuracy: 0.9639 - val_loss: 0.1152\n",
      "Epoch 87/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9637 - loss: 0.0992 - val_accuracy: 0.9531 - val_loss: 0.1071\n",
      "Epoch 88/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9711 - loss: 0.0894 - val_accuracy: 0.9386 - val_loss: 0.1060\n",
      "Epoch 89/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9656 - loss: 0.0917 - val_accuracy: 0.9531 - val_loss: 0.1048\n",
      "Epoch 90/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9680 - loss: 0.0884 - val_accuracy: 0.9531 - val_loss: 0.1027\n",
      "Epoch 91/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9528 - loss: 0.1007 - val_accuracy: 0.9386 - val_loss: 0.1075\n",
      "Epoch 92/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9630 - loss: 0.0942 - val_accuracy: 0.9386 - val_loss: 0.1007\n",
      "Epoch 93/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9618 - loss: 0.0996 - val_accuracy: 0.9458 - val_loss: 0.0999\n",
      "Epoch 94/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9740 - loss: 0.0766 - val_accuracy: 0.9531 - val_loss: 0.1001\n",
      "Epoch 95/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9666 - loss: 0.0861 - val_accuracy: 0.9531 - val_loss: 0.0983\n",
      "Epoch 96/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9642 - loss: 0.0821 - val_accuracy: 0.9531 - val_loss: 0.0963\n",
      "Epoch 97/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9705 - loss: 0.0761 - val_accuracy: 0.9567 - val_loss: 0.0970\n",
      "Epoch 98/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9662 - loss: 0.0763 - val_accuracy: 0.9458 - val_loss: 0.0998\n",
      "Epoch 99/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9667 - loss: 0.0851 - val_accuracy: 0.9567 - val_loss: 0.0990\n",
      "Epoch 100/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9663 - loss: 0.0778 - val_accuracy: 0.9603 - val_loss: 0.0962\n",
      "Epoch 101/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9590 - loss: 0.0962 - val_accuracy: 0.9603 - val_loss: 0.0987\n",
      "Epoch 102/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9745 - loss: 0.0721 - val_accuracy: 0.9603 - val_loss: 0.0919\n",
      "Epoch 103/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9745 - loss: 0.0764 - val_accuracy: 0.9603 - val_loss: 0.0967\n",
      "Epoch 104/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9735 - loss: 0.0735 - val_accuracy: 0.9531 - val_loss: 0.0909\n",
      "Epoch 105/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9766 - loss: 0.0697 - val_accuracy: 0.9603 - val_loss: 0.0964\n",
      "Epoch 106/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9561 - loss: 0.1096 - val_accuracy: 0.9639 - val_loss: 0.0875\n",
      "Epoch 107/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9617 - loss: 0.0797 - val_accuracy: 0.9603 - val_loss: 0.0872\n",
      "Epoch 108/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9698 - loss: 0.0811 - val_accuracy: 0.9567 - val_loss: 0.0894\n",
      "Epoch 109/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9711 - loss: 0.0801 - val_accuracy: 0.9603 - val_loss: 0.0935\n",
      "Epoch 110/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9751 - loss: 0.0718 - val_accuracy: 0.9567 - val_loss: 0.0874\n",
      "Epoch 111/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9706 - loss: 0.0785 - val_accuracy: 0.9567 - val_loss: 0.0870\n",
      "Epoch 112/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9776 - loss: 0.0597 - val_accuracy: 0.9567 - val_loss: 0.0929\n",
      "Epoch 113/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9664 - loss: 0.0763 - val_accuracy: 0.9639 - val_loss: 0.0829\n",
      "Epoch 114/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9715 - loss: 0.0608 - val_accuracy: 0.9711 - val_loss: 0.0812\n",
      "Epoch 115/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9642 - loss: 0.0779 - val_accuracy: 0.9639 - val_loss: 0.0800\n",
      "Epoch 116/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9687 - loss: 0.0695 - val_accuracy: 0.9603 - val_loss: 0.0923\n",
      "Epoch 117/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9773 - loss: 0.0677 - val_accuracy: 0.9531 - val_loss: 0.1015\n",
      "Epoch 118/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9725 - loss: 0.0762 - val_accuracy: 0.9603 - val_loss: 0.0917\n",
      "Epoch 119/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9721 - loss: 0.0666 - val_accuracy: 0.9603 - val_loss: 0.0790\n",
      "Epoch 120/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9685 - loss: 0.0671 - val_accuracy: 0.9783 - val_loss: 0.0749\n",
      "Epoch 121/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9775 - loss: 0.0641 - val_accuracy: 0.9639 - val_loss: 0.0743\n",
      "Epoch 122/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9709 - loss: 0.0663 - val_accuracy: 0.9603 - val_loss: 0.0799\n",
      "Epoch 123/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9719 - loss: 0.0624 - val_accuracy: 0.9603 - val_loss: 0.0758\n",
      "Epoch 124/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9787 - loss: 0.0594 - val_accuracy: 0.9603 - val_loss: 0.0755\n",
      "Epoch 125/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9753 - loss: 0.0719 - val_accuracy: 0.9711 - val_loss: 0.0731\n",
      "Epoch 126/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9757 - loss: 0.0535 - val_accuracy: 0.9603 - val_loss: 0.0752\n",
      "Epoch 127/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9739 - loss: 0.0720 - val_accuracy: 0.9711 - val_loss: 0.0705\n",
      "Epoch 128/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9750 - loss: 0.0597 - val_accuracy: 0.9711 - val_loss: 0.0723\n",
      "Epoch 129/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9712 - loss: 0.0570 - val_accuracy: 0.9711 - val_loss: 0.0713\n",
      "Epoch 130/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9778 - loss: 0.0584 - val_accuracy: 0.9603 - val_loss: 0.0715\n",
      "Epoch 131/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9816 - loss: 0.0616 - val_accuracy: 0.9675 - val_loss: 0.0693\n",
      "Epoch 132/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9759 - loss: 0.0633 - val_accuracy: 0.9783 - val_loss: 0.0685\n",
      "Epoch 133/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9695 - loss: 0.0673 - val_accuracy: 0.9819 - val_loss: 0.0661\n",
      "Epoch 134/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9821 - loss: 0.0628 - val_accuracy: 0.9675 - val_loss: 0.0691\n",
      "Epoch 135/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9809 - loss: 0.0615 - val_accuracy: 0.9603 - val_loss: 0.0706\n",
      "Epoch 136/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9768 - loss: 0.0653 - val_accuracy: 0.9639 - val_loss: 0.0710\n",
      "Epoch 137/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9757 - loss: 0.0520 - val_accuracy: 0.9711 - val_loss: 0.0666\n",
      "Epoch 138/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9907 - loss: 0.0431 - val_accuracy: 0.9819 - val_loss: 0.0635\n",
      "Epoch 139/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9879 - loss: 0.0508 - val_accuracy: 0.9675 - val_loss: 0.0679\n",
      "Epoch 140/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0655 - val_accuracy: 0.9783 - val_loss: 0.0675\n",
      "Epoch 141/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9834 - loss: 0.0535 - val_accuracy: 0.9819 - val_loss: 0.0628\n",
      "Epoch 142/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9858 - loss: 0.0487 - val_accuracy: 0.9747 - val_loss: 0.0624\n",
      "Epoch 143/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9797 - loss: 0.0584 - val_accuracy: 0.9783 - val_loss: 0.0612\n",
      "Epoch 144/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9810 - loss: 0.0530 - val_accuracy: 0.9639 - val_loss: 0.0812\n",
      "Epoch 145/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9799 - loss: 0.0567 - val_accuracy: 0.9783 - val_loss: 0.0606\n",
      "Epoch 146/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9832 - loss: 0.0495 - val_accuracy: 0.9856 - val_loss: 0.0589\n",
      "Epoch 147/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9785 - loss: 0.0569 - val_accuracy: 0.9856 - val_loss: 0.0605\n",
      "Epoch 148/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9892 - loss: 0.0453 - val_accuracy: 0.9711 - val_loss: 0.0608\n",
      "Epoch 149/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9879 - loss: 0.0474 - val_accuracy: 0.9711 - val_loss: 0.0606\n",
      "Epoch 150/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9867 - loss: 0.0449 - val_accuracy: 0.9856 - val_loss: 0.0588\n",
      "Epoch 151/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9807 - loss: 0.0468 - val_accuracy: 0.9783 - val_loss: 0.0590\n",
      "Epoch 152/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9723 - loss: 0.0604 - val_accuracy: 0.9711 - val_loss: 0.0597\n",
      "Epoch 153/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9855 - loss: 0.0454 - val_accuracy: 0.9819 - val_loss: 0.0569\n",
      "Epoch 154/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9854 - loss: 0.0490 - val_accuracy: 0.9856 - val_loss: 0.0572\n",
      "Epoch 155/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9781 - loss: 0.0531 - val_accuracy: 0.9711 - val_loss: 0.0654\n",
      "Epoch 156/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9858 - loss: 0.0451 - val_accuracy: 0.9856 - val_loss: 0.0552\n",
      "Epoch 157/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9861 - loss: 0.0460 - val_accuracy: 0.9639 - val_loss: 0.0694\n",
      "Epoch 158/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9744 - loss: 0.0591 - val_accuracy: 0.9856 - val_loss: 0.0540\n",
      "Epoch 159/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9842 - loss: 0.0525 - val_accuracy: 0.9856 - val_loss: 0.0535\n",
      "Epoch 160/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9897 - loss: 0.0476 - val_accuracy: 0.9856 - val_loss: 0.0527\n",
      "Epoch 161/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9880 - loss: 0.0488 - val_accuracy: 0.9892 - val_loss: 0.0537\n",
      "Epoch 162/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9888 - loss: 0.0444 - val_accuracy: 0.9783 - val_loss: 0.0579\n",
      "Epoch 163/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9866 - loss: 0.0458 - val_accuracy: 0.9856 - val_loss: 0.0527\n",
      "Epoch 164/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9817 - loss: 0.0513 - val_accuracy: 0.9856 - val_loss: 0.0512\n",
      "Epoch 165/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9939 - loss: 0.0371 - val_accuracy: 0.9747 - val_loss: 0.0547\n",
      "Epoch 166/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9880 - loss: 0.0423 - val_accuracy: 0.9892 - val_loss: 0.0511\n",
      "Epoch 167/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9917 - loss: 0.0365 - val_accuracy: 0.9892 - val_loss: 0.0514\n",
      "Epoch 168/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9854 - loss: 0.0545 - val_accuracy: 0.9892 - val_loss: 0.0515\n",
      "Epoch 169/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9892 - loss: 0.0354 - val_accuracy: 0.9856 - val_loss: 0.0491\n",
      "Epoch 170/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9832 - loss: 0.0516 - val_accuracy: 0.9819 - val_loss: 0.0547\n",
      "Epoch 171/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9862 - loss: 0.0382 - val_accuracy: 0.9819 - val_loss: 0.0486\n",
      "Epoch 172/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9822 - loss: 0.0429 - val_accuracy: 0.9819 - val_loss: 0.0496\n",
      "Epoch 173/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9897 - loss: 0.0369 - val_accuracy: 0.9819 - val_loss: 0.0516\n",
      "Epoch 174/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9897 - loss: 0.0387 - val_accuracy: 0.9892 - val_loss: 0.0476\n",
      "Epoch 175/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9896 - loss: 0.0388 - val_accuracy: 0.9892 - val_loss: 0.0497\n",
      "Epoch 176/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9887 - loss: 0.0344 - val_accuracy: 0.9711 - val_loss: 0.0615\n",
      "Epoch 177/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9828 - loss: 0.0427 - val_accuracy: 0.9892 - val_loss: 0.0452\n",
      "Epoch 178/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9880 - loss: 0.0346 - val_accuracy: 0.9892 - val_loss: 0.0490\n",
      "Epoch 179/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9870 - loss: 0.0409 - val_accuracy: 0.9892 - val_loss: 0.0454\n",
      "Epoch 180/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9932 - loss: 0.0390 - val_accuracy: 0.9819 - val_loss: 0.0503\n",
      "Epoch 181/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9918 - loss: 0.0444 - val_accuracy: 0.9892 - val_loss: 0.0438\n",
      "Epoch 182/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9929 - loss: 0.0335 - val_accuracy: 0.9892 - val_loss: 0.0424\n",
      "Epoch 183/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9862 - loss: 0.0414 - val_accuracy: 0.9892 - val_loss: 0.0435\n",
      "Epoch 184/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9905 - loss: 0.0366 - val_accuracy: 0.9892 - val_loss: 0.0433\n",
      "Epoch 185/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9946 - loss: 0.0373 - val_accuracy: 0.9892 - val_loss: 0.0444\n",
      "Epoch 186/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9911 - loss: 0.0366 - val_accuracy: 0.9892 - val_loss: 0.0410\n",
      "Epoch 187/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9866 - loss: 0.0431 - val_accuracy: 0.9892 - val_loss: 0.0415\n",
      "Epoch 188/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9926 - loss: 0.0340 - val_accuracy: 0.9892 - val_loss: 0.0401\n",
      "Epoch 189/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9902 - loss: 0.0338 - val_accuracy: 0.9892 - val_loss: 0.0408\n",
      "Epoch 190/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9902 - loss: 0.0365 - val_accuracy: 0.9928 - val_loss: 0.0446\n",
      "Epoch 191/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9919 - loss: 0.0458 - val_accuracy: 0.9928 - val_loss: 0.0431\n",
      "Epoch 192/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9871 - loss: 0.0387 - val_accuracy: 0.9892 - val_loss: 0.0399\n",
      "Epoch 193/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9916 - loss: 0.0304 - val_accuracy: 0.9892 - val_loss: 0.0390\n",
      "Epoch 194/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9914 - loss: 0.0278 - val_accuracy: 0.9892 - val_loss: 0.0388\n",
      "Epoch 195/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9958 - loss: 0.0263 - val_accuracy: 0.9892 - val_loss: 0.0376\n",
      "Epoch 196/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9896 - loss: 0.0294 - val_accuracy: 0.9892 - val_loss: 0.0393\n",
      "Epoch 197/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9944 - loss: 0.0312 - val_accuracy: 0.9892 - val_loss: 0.0366\n",
      "Epoch 198/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9890 - loss: 0.0368 - val_accuracy: 0.9747 - val_loss: 0.0611\n",
      "Epoch 199/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9869 - loss: 0.0382 - val_accuracy: 0.9892 - val_loss: 0.0363\n",
      "Epoch 200/200\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9886 - loss: 0.0366 - val_accuracy: 0.9928 - val_loss: 0.0395\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f8e2b05000>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "model.fit(X_train, y_train, \n",
    "          epochs=200, \n",
    "          validation_data=(X_test, y_test),\n",
    "          batch_size=32,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b5827e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9795 - loss: 0.0505 \n",
      "Test Accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_acc:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
